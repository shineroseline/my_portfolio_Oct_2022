{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      my_blobs\n",
      "1  <function make_blobs at 0x000002186493A310>\n",
      "2  <function make_blobs at 0x000002186493A310>\n",
      "3  <function make_blobs at 0x000002186493A310>\n"
     ]
    }
   ],
   "source": [
    "#unsupervised learning using Kmeans Algorithm\n",
    "#How to import random sample generator to create a dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs  #how to import random samples generator to create a dataset using make_\n",
    "n=make_blobs\n",
    "df_blobs=pd.DataFrame({\"my_blobs\":make_blobs}, index=[\"1\",\"2\",\"3\"])\n",
    "print(df_blobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=300\n",
    "random_state=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 2, 1, 1, 0, 0, 0, 2, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2,\n",
       "       2, 0, 2, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2,\n",
       "       0, 0, 2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 1, 0, 0, 1, 1, 2, 2, 1, 1, 0,\n",
       "       2, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0, 0, 2,\n",
       "       0, 2, 2, 0, 2, 1, 1, 0, 2, 1, 0, 0, 2, 0, 2, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 2, 0, 0, 2, 2, 1, 2, 1, 0, 2, 0, 2, 2, 2, 0, 1, 0, 0, 1, 0,\n",
       "       2, 2, 0, 2, 2, 2, 0, 2, 1, 0, 0, 1, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2,\n",
       "       1, 1, 2, 2, 2, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 2,\n",
       "       0, 0, 0, 1, 0, 1, 2, 1, 2, 2, 1, 2, 0, 0, 0, 0, 2, 1, 0, 2, 1, 2,\n",
       "       2, 2, 1, 0, 2, 0, 2, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 1, 2, 0, 1,\n",
       "       2, 1, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 1, 2, 0, 0, 0, 0, 1, 0, 2,\n",
       "       1, 0, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 2, 1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=make_blobs(n_samples=n_samples, n_features=5, random_state=None)\n",
    "predict_y=KMeans(n_clusters=3, random_state=random_state).fit_predict(x)\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIMENSIONALITY REDUCTION USING PCA #PRINCIPAL COMPONENT ANALYSIS\n",
    "#FIRST WE GENERATE RANDOM SAMPLES OF DIMENSION 20\n",
    "from sklearn.datasets import make_blobs\n",
    "n_samples=500\n",
    "random_state=50\n",
    "x,y=make_blobs(n_samples=n_samples, n_features=20, random_state=None)   #random_state is set to none to return all the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape      #the dataset has 500rows 20 col(attributes or features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next task is to reduce the dimension of the dataset by reducing the no of features from 20 to 7\n",
    "from sklearn.decomposition import PCA\n",
    "#we reduce the number of components from 20 to 7\n",
    "pca=PCA(n_components=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we fit the data into the model\n",
    "pca.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61211266 0.33633816 0.00384504 0.00369604 0.003513   0.00342149\n",
      " 0.0033409 ]\n"
     ]
    }
   ],
   "source": [
    "#use the explained variance ratio to view the percentage of variance explained by this component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25895387  0.13186691 -0.12134796 -0.37079895 -0.03093433  0.05198107\n",
      " -0.23573507 -0.17844937  0.25113793  0.38100049  0.03405935  0.15353762\n",
      "  0.0081175  -0.52439516 -0.09216578 -0.03779269  0.21166506 -0.07143759\n",
      "  0.31719929  0.06162286]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_[0]) #to view the first pca component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5533691  -0.00843783  0.12857602 -0.20311881  0.13254525 -0.11246621\n",
      "  0.13287266  0.42913866 -0.11981042  0.16449089 -0.11685243  0.44827276\n",
      "  0.22177515 -0.03424508 -0.17239798 -0.068679    0.18209829  0.07940867\n",
      "  0.12465247 -0.08987242]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we apply the dimensionality reduction\n",
    "pca_reduced=pca.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_reduced.shape  #the reduced datasets now has 500 observations and 3 features(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline is used to chain several models orestimators\n",
    "#we demonstrate wit linear model, pca model and logistic model\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.linear_model import LogisticRegression#logistic regression is not a transformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we chain the estimators\n",
    "estimators=[('dimension_reduction', PCA()),(\"linear_regression\",LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dimension_reduction', PCA()), ('linear_regression', LinearRegression())]\n"
     ]
    }
   ],
   "source": [
    "print(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a pipeline object and pass the chain estimator into it.\n",
    "pipeline_estimator=Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dimension_reduction', PCA())"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimator.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('linear_regression', LinearRegression())"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimator.steps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dimension_reduction', PCA()), ('linear_regression', LinearRegression())]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimator.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
